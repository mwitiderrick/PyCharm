# -*- coding: utf-8 -*-
"""cnn cnvrg.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XGVvecQnr86wwxkCFebpHt3Z8tYiVWO-
"""

import tensorflow as tf

print(tf.__version__)

(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()

import matplotlib.pyplot as plt

image = X_train[785]
plt.imshow(image)
plt.show()

y_train[785]

X_train = X_train / 255
X_test = X_test / 255

model = tf.keras.Sequential(
    [
        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation="relu", input_shape=(32, 32, 3)),
        tf.keras.layers.MaxPooling2D((2, 2), strides=2),

        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation="relu"),
        tf.keras.layers.MaxPooling2D((2, 2), strides=2),

        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(100, activation="relu"),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(10, activation="softmax")
    ]
)

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.summary()

tf.keras.utils.plot_model(
    model,
    to_file="model.png",
    show_shapes=True,
    show_layer_names=True,
    rankdir="TB",
    expand_nested=True,
    dpi=96,
)

checkpoint_filepath = '/tmp/checkpoint'
model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=False,
    monitor='loss',
    mode='min',
    save_best_only=True)

from tensorflow.keras.callbacks import EarlyStopping

callbacks = [
    EarlyStopping(patience=2),
    model_checkpoint_callback,

]

history = model.fit(X_train, y_train, epochs=600, validation_data=(X_test, y_test), callbacks=callbacks)

loss, accuracy = model.evaluate(X_test, y_test)
print('Accuracy on test dataset:', accuracy)

predictions = model.predict(X_test)

import numpy as np

np.argmax(model.predict(X_test[60].reshape(1, 32, 32, 3)), axis=-1)

y_test[60]

import pandas as pd

metrics_df = pd.DataFrame(history.history)

metrics_df

metrics_df[["loss", "val_loss"]].plot();

metrics_df[["accuracy", "val_accuracy"]].plot();

model.save("model.h5")

load_saved_model = tf.keras.models.load_model("model.h5")

load_saved_model.summary()

another_saved_model = tf.keras.models.load_model(checkpoint_filepath)

another_saved_model.summary()

"""# Model with Batch Normalization"""

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()

x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.Sequential(
    [
        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation="relu", input_shape=(32, 32, 3)),
        tf.keras.layers.MaxPooling2D((2, 2), strides=2),

        tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation="relu"),
        tf.keras.layers.MaxPooling2D((2, 2), strides=2),

        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(100, activation="relu"),
        tf.keras.layers.BatchNormalization(),
        tf.keras.layers.Dense(10, activation="softmax")
    ]
)

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(x_train, y_train, epochs=600, validation_data=(x_test, y_test),
                    callbacks=callbacks
                    )

loss, accuracy = model.evaluate(x_test, y_test)
print('Accuracy on test dataset:', accuracy)

"""# Running CNN on TensorFlow in the real world"""

data_folder = tf.keras.utils.get_file(
    'flower_photos',
    'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',
    untar=True)

data_folder

import os

os.listdir(data_folder)

training_set = tf.keras.preprocessing.image_dataset_from_directory(
    data_folder,
    validation_split=0.2,
    subset="training",
    seed=101,
    image_size=(150, 150),
    batch_size=32)

validation_set = tf.keras.preprocessing.image_dataset_from_directory(
    data_folder,
    validation_split=0.2,
    subset="validation",
    seed=101,
    image_size=(150, 150),
    batch_size=32)

class_names = training_set.class_names
print(class_names)

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator

data_augmentation = keras.Sequential(
    [
        tf.keras.layers.experimental.preprocessing.RandomFlip("horizontal",
                                                              input_shape=(150,
                                                                           150,
                                                                           3)),
        tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),
        tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),
    ]
)

model = Sequential([
    data_augmentation,
    tf.keras.layers.experimental.preprocessing.Rescaling(1. / 255),
    Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),

    Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),

    Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.25),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.25),
    Dense(5, activation='softmax')
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(training_set, validation_data=validation_set, epochs=600, callbacks=callbacks)

import pandas as pd

metrics_df = pd.DataFrame(history.history)

metrics_df[["loss", "val_loss"]].plot();

metrics_df[["accuracy", "val_accuracy"]].plot();

roses = "https://upload.wikimedia.org/wikipedia/commons/4/45/A_Sunflower.jpg"
roses_path = tf.keras.utils.get_file('Red_sunflower', origin=roses)

import numpy as np

img = keras.preprocessing.image.load_img(
    roses_path, target_size=(150, 150)
)
img_array = keras.preprocessing.image.img_to_array(img)
img_array = tf.expand_dims(img_array, 0)  # Create a batch

predictions = model.predict(img_array)
score = tf.nn.softmax(predictions[0])

print(
    "This image most likely belongs to {} with a {:.2f} percent confidence."
        .format(class_names[np.argmax(score)], 100 * np.max(score))
)

sunflower_url = "https://pixnio.com/free-images/2018/12/02/2018-12-02-15-56-45.jpg"
sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)

img = keras.preprocessing.image.load_img(
    sunflower_path, target_size=(150, 150)
)
img_array = keras.preprocessing.image.img_to_array(img)
img_array = tf.expand_dims(img_array, 0)  # Create a batch

predictions = model.predict(img_array)
score = tf.nn.softmax(predictions[0])

print(
    "This image most likely belongs to {} with a {:.2f} percent confidence."
        .format(class_names[np.argmax(score)], 100 * np.max(score)))

img_array.numpy().max()

